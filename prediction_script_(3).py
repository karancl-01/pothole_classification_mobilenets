# -*- coding: utf-8 -*-
"""prediction_script_(2)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eb866ofOfBmZxEGD9tEGgHbvE6iRmrZt
"""

import sys
import os
from PIL import Image
import torch
import torch.nn as nn
from torchvision import models, transforms
# We still need fastai for the architecture helpers to perfectly match the training structure
from fastai.vision.all import create_body, create_head, num_features_model

# special check to see if the code is running in a Google Colab notebook.
# If it is, we import the 'files' library for the upload button.
IN_COLAB = 'google.colab' in sys.modules
if IN_COLAB:
    from google.colab import files

# This function encapsulates the prediction logic using a .pth file.
def get_infra_prediction(model_path, image_path, device, class_names):
    """
    Loads a trained model (.pth) whose architecture was defined by fastai
    and predicts the class of a single image.
    """
    try:

        # We must replicate the exact nn.Sequential(body, head) structure from fastai.

        # First, load the base MobileNetV2 architecture to get the building blocks.
        pretrained_model = models.mobilenet_v2()


        body = create_body(pretrained_model, cut=-1)

        head = create_head(nf=num_features_model(body), n_out=len(class_names))

        # Combine them into the final model structure. This now matches the training architecture.
        model = nn.Sequential(body, head)


        # the correct way to load a .pth file.
        model.load_state_dict(torch.load(model_path, map_location=device))
        model = model.to(device)
        model.eval() # Set the model to evaluation mode. This is crucial.

        #  the necessary image transformations.
        prediction_transforms = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        # 4. Open and transform the image.
        image = Image.open(image_path).convert("RGB")
        image_tensor = prediction_transforms(image).unsqueeze(0).to(device)

        # 5. Make the prediction.
        with torch.no_grad():
            outputs = model(image_tensor)
            probs = torch.nn.functional.softmax(outputs, dim=1)
            confidence, preds = torch.max(probs, 1)
            predicted_class = class_names[preds[0]]

        return {
            "prediction": str(predicted_class),
            "confidence": f"{float(confidence) * 100:.2f}%"
        }

    except FileNotFoundError:
        return {"error": f"Model or image file not found. Check paths."}
    except Exception as e:
        return {"error": f"An error occurred during prediction: {e}"}

# This block of code only runs when you execute the script directly.
if __name__ == '__main__':
    model_weights_path = 'infra_classifier_model.pth'

    # Check if the model file exists first.
    if not os.path.exists(model_weights_path):
        print(f"Error: Model weights file not found at '{model_weights_path}'")
        print("Please ensure the exported 'infra_classifier_model.pth' is in the same directory.")
    else:
        image_to_predict = None
        # Check if we are in a Colab environment to decide how to get the image.
        if IN_COLAB:
            print("Please upload an image file to classify.")
            uploaded = files.upload()
            if uploaded:
                image_to_predict = next(iter(uploaded))
        else:
            # Fallback to command-line or text input if not in Colab.
            if len(sys.argv) > 1:
                image_to_predict = sys.argv[1]
            else:
                image_to_predict = input("Please enter the path to your image file: ")

        if image_to_predict and os.path.exists(image_to_predict):
            device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            class_names = ['garbage_dumps', 'pothole', 'transmission_wires']

            print("\nLoading model and making prediction...")
            result = get_infra_prediction(model_weights_path, image_to_predict, device, class_names)

            if "error" in result:
                print(f"An error occurred: {result['error']}")
            else:

                print(f"{result['prediction']}")

        else:
            if image_to_predict:
                 print(f"Error: Image file not found at '{image_to_predict}'")
            else:
                print("No image file provided.")

